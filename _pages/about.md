---
permalink: /
title: "About"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi, I am Samyadeep Basu, a 2nd year (3rd semester) CS PhD student at UMD, College Park (2022 - Present). I work with [Soheil Feizi](https://www.cs.umd.edu/~sfeizi/) in the [Center for Machine Learning](https://ml.umd.edu/). My research focus is to learn from data with limited supervision (few-shot learning), model interpretability (how to understand decision making process of deep networks), robustness and more recently vision+language. Previously I received my MS from UMD in 2020 and then spent close to two years at Microsoft AI in the [ML rotation program](https://www.microsoftnewengland.com/maidap/). During my stint at Microsoft AI, I worked with the Language Science Team at [Azure AI](https://www.microsoft.com/en-us/research/group/cognitive-services-research/knowledge-and-language/) and [MSAI](https://www.microsoft.com/en-us/research/group/artificial-intelligence-research-munich/) where I researched, developed and deployed large-scale language models for various scenarios.

News 
======
 (July 2023): Excited to announce two new projects : (i) Improving CLIP using knowledge distillation from diffusion models; (ii) Benchmark for text-guided  image editing methods! 
 
 (June 2023): Started internship at Adobe Research! Working on interpretability + model editing for text-to-image generative models!
 
 (April 2023): Our new pre-print on PEFT modules for few-shot fine-tuning is on [arXiv](https://arxiv.org/abs/2304.01917)!
 
 (Jan 2023): 1st Paper from PhD accepted at ICLR 2023!
 
 (September 2022): Finished an amazing research internship at [Microsoft Research](https://www.microsoft.com/en-us/research/) working with [Daniela Massiceti](https://www.microsoft.com/en-us/research/people/dmassiceti/) on few-shot learning!
 
 (Feb 2022): Started my PhD to work on few-shot learning and model interpretability!

Publications
======
1. [Augmenting CLIP with Improved Visio-Linguistic Reasoning](https://arxiv.org/abs/2307.09233)

   **Under Review**
   > We propose a knowledge-distillation technique to improve reasoning abilities in CLIP!
     
2. [Benchmarking Text-Guided Image Editing Methods](https://samyadeepbasu.github.io)
 
   **Under Review** [Code Coming Soon!](https://samyadeepbasu.github.io)
  > We propose a new comprehensive benchmark for evaluating diffusion based editing methods!
    
3. [Strong Baselines for Parameter-Efficient Few-Shot Fine-Tuning](https://arxiv.org/abs/2304.01917) 

   **Under Review** [Code](https://github.com/Samyadeep/)
  > We propose two easy-to-implement strong baselines for PEFT which leads to SoTA on MD!
4. [Hard Meta-Dataset++: Towards Understanding Few-shot Performance on Difficult Tasks](https://openreview.net/pdf?id=wq0luyH3m4) 

   **ICLR 2023** [Code](https://github.com/Samyadeep/HardMD)
  > We propose a fast algorithm - FastDiffSel which can extract difficult few-shot tasks in a computational efficient way from large vision datasets!
5. [Strategies to Improve Few-Shot Learning for Intent Classification and Slot Filling](https://arxiv.org/abs/2109.08754) 

   **NAACL 2022 (SUKI)**
  > Propose empirical strategies to improve few-shot performance for joint intent classification and slot-filling.
6. [Influence Functions in Deep Learning are Fragile](https://arxiv.org/abs/2006.14651) 
    
    **ICLR 2021**
  > End to end analysis of influence functions in deep learning!
7. [On Second-Order Group Influence Functions for Black-Box Predictions](http://proceedings.mlr.press/v119/basu20b.html) 

   **ICML 2020**
  > We propose second-order group influence functions, which are better suited to handle group effects!
8. [Membership Model Inversion Attacks for Deep Networks](https://arxiv.org/abs/1910.04257)
  
   **NeurIPS 2020(w)**
  > We propose an early inversion technique using GANs to do membership inference!
9. [Topic Segmentation in the Wild: Towards Segmentation of Semi-Structured and Unstructured Data](https://neurips2022-enlsp.github.io/) 

   **NeurIPS 2022 - ENLSP**
  > Understanding the efficacy of topic segmentation models on unstructured texts.

